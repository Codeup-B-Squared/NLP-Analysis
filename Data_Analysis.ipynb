{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project<a class=\"anchor\" id=\"top\"></a>\n",
    "## Team Members\n",
    "[Bethany Thompson](https://github.com/ThompsonBethany01) & [Bibek Mainali](https://github.com/MainaliB)\n",
    "## Goals \n",
    "Predict a repository coding language by it's readme file.\n",
    "- Acquire data on GitHub's trending repositories\n",
    "- Clean data by normalizing any text\n",
    "- Explore trends in text within each coding language\n",
    "- Create a classification model to predict the coding language\n",
    "\n",
    "## Conclusions\n",
    "- Trends:\n",
    "- Model Metrics:\n",
    "\n",
    "## Reproduction Requirements\n",
    "### Files\n",
    "In your working directory, download:\n",
    "- Data_Analysis.ipynb\n",
    "- Acquire.py\n",
    "- Prepare.py  \n",
    "\n",
    "Tools:\n",
    "- Python Version\n",
    "- Pandas Version\n",
    "- Other Versions\n",
    "\n",
    "## Table of Contents\n",
    "1. [Acquisition](#first-bullet)\n",
    "2. [Preparation](#second-bullet)\n",
    "3. [Exploration](#third-bullet)\n",
    "4. [Modeling](#fourth-bullet)\n",
    "5. [Final Conclusions](#fifth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "For this project, we have to build the dataset. We decided on a list of GitHub repositories to scrape, and wrote the python code necessary to extract the text of the README file for each page, and the primary language of the repository.\n",
    "\n",
    "To can find the language of a repository:\n",
    "1. Visit Main Page of Repo\n",
    "1. Locate Bottom Right Side of Repo stating **Languages** \n",
    "2. html code ```<ul class=\"list-style-none\">```\n",
    "\n",
    "The only requirement is to include at least 100 repositories in our data set.\n",
    "\n",
    "## Repositories Chosen\n",
    "- GitHub's Trending English Repositories - At Least 25 from Top 4 Most Popular Coding Languages\n",
    "     - Python\n",
    "     - Java\n",
    "     - Swift\n",
    "     - Something Else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Acquire.py Module\n",
    "import Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire.get_top_repo Function\n",
    "- Scrapes repository names from the trending GitHub repo page, acquiring 25 from each coding language filter of Python, Java, Javescript, and Swift\n",
    "- creates url from repo name user/repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls = Acquire.get_top_repo(['python','java','javascript','swift'],'daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no repeat urls present\n",
    "# urls.link.value_counts()[urls.link.value_counts() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected amount of coding languages\n",
    "# urls.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire.get_content_df Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code ran once for acquire and prep, final df saved to csv after prepare\n",
    "# df = Acquire.get_content_df(urls['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "Our df includes:\n",
    "- content as Readme file text\n",
    "- watchers as number of users watching the repo\n",
    "- stars as number of users that have starred the repo\n",
    "- forks as number of users that have forked the repo\n",
    "\n",
    "Next steps:\n",
    "1. clean the text file\n",
    "2. convert counts from strings to integeres, i.e. 1.5k to 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "Within the Prepare.py function:\n",
    "- readme file text is normalized using Natural Language Processing\n",
    "- string numbers are converted to integers using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = Prepare.prepare_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.merge(urls, left_on=df.index, right_on=urls.index).drop('key_0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will work with this df from now up to testing the final model chosen\n",
    "# will generate new data later to evaluate the final model on test\n",
    "# df.to_csv('train_validate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_validate.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "Conclusions:  \n",
    "Next Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "### Before splitting the df, we can do univariate exploration:\n",
    "   - distributions of single variables\n",
    "   - determine if outliers are present - are they okay in the context or need to be removed?  \n",
    "\n",
    "\n",
    "### Split the data into train and validate for bivariate analysis\n",
    "   - What are the most common words in READMEs?\n",
    "   - What does the distribution of IDFs look like for the most common words?\n",
    "   - Does the length of the README vary by programming language?\n",
    "   - Do different programming languages use a different number of unique words?\n",
    "   - What words are present only within the specific coding languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('figure', figsize = [13,9])\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis Before Splitting the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "plt.figure(figsize=(13,9))\n",
    "for col in df.describe():\n",
    "    \n",
    "    plt.subplot(3,2,x)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count of Repos')\n",
    "    plt.hist(df[col])\n",
    "    x = x + 1\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the DF Into Train and Validate for Bivariate Analysis and Modeling\n",
    "- Prepare Function Splits DF Into 68% Train, 32% Validate\n",
    "    - 17 observations from each lanuage for Train\n",
    "    - 8 observations from each language for Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train percent:  68.0 , validate percent:  32.0\n"
     ]
    }
   ],
   "source": [
    "train, validate = Prepare.train_validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "javascript    18\n",
       "java          18\n",
       "python        16\n",
       "swift         16\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Train DF Only\n",
    "### Plotting Word Probability by Langauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_words = ' '.join(train[train.language == 'python'].filtered)\n",
    "java_words = ' '.join(train[train.language == 'java'].filtered)\n",
    "javascript_words = ' '.join(train[train.language == 'javascript'].filtered)\n",
    "swift_words = ' '.join(train[train.language == 'swift'].filtered)\n",
    "all_words = ' '.join(train.filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_words = re.sub(r'\\s.\\s', '', python_words)\n",
    "java_words = re.sub(r'\\s.\\s', '', java_words)\n",
    "javascript_words = re.sub(r'\\s.\\s', '', javascript_words)\n",
    "swift_words = re.sub(r'\\s.\\s', '', swift_words)\n",
    "all_words = re.sub(r'\\s.\\s', '', all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_words_freq = pd.Series(python_words.split()).value_counts()\n",
    "java_words_freq = pd.Series(java_words.split()).value_counts()\n",
    "javascript_words_freq = pd.Series(javascript_words.split()).value_counts()\n",
    "swift_words_freq = pd.Series(swift_words.split()).value_counts()\n",
    "all_words_freq = pd.Series(all_words.split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = (pd.concat([all_words_freq, python_words_freq, java_words_freq, javascript_words_freq, swift_words_freq], axis=1, sort=True)\n",
    "              .set_axis(['all','python', 'java', 'javascript', 'swift'], axis=1, inplace=False)\n",
    "              .fillna(0).apply(lambda s: s.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the proportion of different languages amongst the top 50 occuring words\n",
    "\n",
    "word_count.assign(p_python = word_count.python/word_count['all'],\n",
    "                  p_java = word_count.java/word_count['all'],\n",
    "                  p_javascript = word_count.javascript/word_count['all'],\n",
    "                  p_swift = word_count.swift/word_count['all']).sort_values(by = 'all')[['p_python', 'p_java', 'p_javascript', 'p_swift']].tail(30).sort_values('p_python').plot.barh(width=.75,stacked = True, color={'darkseagreen','lightsteelblue','teal','thistle'}).legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    \n",
    "plt.title('Proportion of 30 Most Common Words by Language Within Our Sample', size=17)\n",
    "plt.yticks(size=13)\n",
    "plt.xticks(size=15)\n",
    "plt.savefig('word_prob.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Single Word Clouds by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word cloud for all of the different programming languages\n",
    "python_cloud = WordCloud(background_color = 'white', height = 1000, width = 1000).generate(python_words)\n",
    "java_cloud = WordCloud(background_color = 'white', height = 1000, width = 1000).generate(java_words)\n",
    "javascript_cloud = WordCloud(background_color = 'white', height = 1000, width = 1000).generate(javascript_words)\n",
    "swift_cloud = WordCloud(background_color = 'white', height = 1000, width = 1000).generate(swift_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the word cloud\n",
    "fig, axes = plt.subplots(2,2, figsize = (13,13))\n",
    "axes[0,0].imshow(python_cloud)\n",
    "axes[0,0].set_title('Python Cloud', size=20)\n",
    "axes[0,1].imshow(java_cloud)\n",
    "axes[0,1].set_title('Java Cloud', size=20)\n",
    "axes[1,0].imshow(javascript_cloud)\n",
    "axes[1,0].set_title('JavaScript Cloud', size=20)\n",
    "axes[1,1].imshow(swift_cloud)\n",
    "axes[1,1].set_title('Swift Cloud', size=20)\n",
    "\n",
    "plt.savefig('word_clouds.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Word Cloud of Complete Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cloud = WordCloud(background_color = 'white', height = 1000, width = 1000).generate(all_words)\n",
    "plt.imshow(all_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Bi-gram Word Clouds by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_bigrams = pd.Series(list(nltk.ngrams(python_words.split(), 2))).value_counts().head(25)\n",
    "java_bigrams = pd.Series(list(nltk.ngrams(java_words.split(), 2))).value_counts().head(25)\n",
    "javascript_bigrams = pd.Series(list(nltk.ngrams(javascript_words.split(), 2))).value_counts().head(25)\n",
    "swift_bigrams = pd.Series(list(nltk.ngrams(swift_words.split(), 2))).value_counts().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_bigrams.sort_values().plot.barh(color='lightsteelblue', width=.9, figsize=(10, 6))\n",
    "    \n",
    "plt.title('25 Most Frequently Occuring Java Bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swift_bigrams.sort_values().plot.barh(color='thistle', width=.9, figsize=(10, 6))\n",
    "    \n",
    "plt.title('25 Most Frequently Occuring Java Bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "python_bigrams.sort_values().plot.barh(color='darkseagreen', width=.9, figsize=(10, 6))\n",
    "    \n",
    "plt.title('25 Most Frequently Occuring Python Bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_bigrams.sort_values().plot.barh(color='teal', width=.9, figsize=(10, 6))\n",
    "    \n",
    "plt.title('25 Most Frequently Occuring Java Bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_data = {k[0] + ' ' + k[1]: v for k, v in python_bigrams.to_dict().items()}\n",
    "java_data = {k[0] + ' ' + k[1]: v for k, v in java_bigrams.to_dict().items()}\n",
    "javascript_data = {k[0] + ' ' + k[1]: v for k, v in javascript_bigrams.to_dict().items()}\n",
    "swift_data = {k[0] + ' ' + k[1]: v for k, v in swift_bigrams.to_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the bigram cloud\n",
    "cloud_python = WordCloud(background_color = 'white', height = 1000, width = 1000)\\\n",
    ".generate_from_frequencies(python_data)\n",
    "\n",
    "cloud_java = WordCloud(background_color = 'white', height = 1000, width = 1000).\\\n",
    "generate_from_frequencies(java_data)\n",
    "\n",
    "cloud_javascript = WordCloud(background_color = 'white', height = 1000, width = 1000).\\\n",
    "generate_from_frequencies(javascript_data)\n",
    "\n",
    "cloud_swift = WordCloud(background_color = 'white', height = 1000, width = 1000).\\\n",
    "generate_from_frequencies(swift_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the bigram word cloud\n",
    "fig, axes = plt.subplots(2,2, figsize = (13,13))\n",
    "axes[0,0].imshow(cloud_python)\n",
    "axes[0,0].set_title('Python Cloud Bigrams')\n",
    "axes[0,1].imshow(cloud_java)\n",
    "axes[0,1].set_title('Java Cloud Bigrams')\n",
    "axes[1,0].imshow(cloud_javascript)\n",
    "axes[1,0].set_title('JavaScript Cloud Bigrams')\n",
    "axes[1,1].imshow(cloud_swift)\n",
    "axes[1,1].set_title('Swift Cloud Bigrams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Frequency of Bigrams by Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do any features correlate with Word_Length?\n",
    "- not including word_length and char_length, which are derived from the same feature\n",
    "- what if we control for language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = (train[['language','word_length','watchers','stars','forks']].corr())\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, annot=True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.title('Correlation Heatmap for All Observations', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "y = 1\n",
    "\n",
    "for x in ['python','java','javascript','swift']:\n",
    "    \n",
    "    plt.subplot(2,2,y)\n",
    "    \n",
    "    # Compute the correlation matrix\n",
    "    corr = (train[train[['language','word_length','watchers','stars','forks']].language == x].corr())\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1,center=0, annot=True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "    plt.title(f'Correlation Heatmap for {x}', size = 20)\n",
    "    \n",
    "    y+=1\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('language_corr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Document Length by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "# Plot the orbital period with horizontal boxes\n",
    "sns.boxplot(x=\"word_length\", y=\"language\", data=train,\n",
    "            whis=[0, 100], width=.6, palette=\"vlag\")\n",
    "\n",
    "# Add in points to show each observation\n",
    "sns.stripplot(x=\"word_length\", y=\"language\", data=train,\n",
    "              size=4, color=\".3\", linewidth=0)\n",
    "\n",
    "# Tweak the visual presentation\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "sns.despine(trim=True, left=True)\n",
    "\n",
    "plt.title('Distribution of Word Length by Language', size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Stars, Watchers, and Forks Significantly Vary by Language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "# Show the joint distribution using kernel density estimation\n",
    "g = sns.jointplot(\n",
    "    data=train,\n",
    "    x=\"stars\", y=\"word_length\", hue=\"language\",\n",
    "    kind=\"kde\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "# Show the joint distribution using kernel density estimation\n",
    "g = sns.jointplot(\n",
    "    data=train,\n",
    "    x=\"watchers\", y=\"word_length\", hue=\"language\",\n",
    "    kind=\"kde\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "# Show the joint distribution using kernel density estimation\n",
    "g = sns.jointplot(\n",
    "    data=train,\n",
    "    x=\"forks\", y=\"word_length\", hue=\"language\",\n",
    "    kind=\"kde\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "Conclusions:  \n",
    "Next Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk  \n",
    "import random  \n",
    "import string\n",
    "import bs4 as bs  \n",
    "import urllib.request  \n",
    "import re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bethanythompson/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "https://stackabuse.com/python-for-nlp-creating-bag-of-words-model-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {}\n",
    "for sentence in corpus:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    for token in tokens:\n",
    "        if token not in wordfreq.keys():\n",
    "            wordfreq[token] = 1\n",
    "        else:\n",
    "            wordfreq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'youtubedl': 119,\n",
       " 'download': 136,\n",
       " 'videos': 73,\n",
       " 'from': 542,\n",
       " 'youtubecom': 2,\n",
       " 'or': 747,\n",
       " 'other': 130,\n",
       " 'video': 189,\n",
       " 'platformsinstallationdescriptionoptionsconfigurationoutput': 1,\n",
       " 'templateformat': 1,\n",
       " 'selectionvideo': 1,\n",
       " 'selectionfaqdeveloper': 1,\n",
       " 'instructionsembedding': 1,\n",
       " 'youtubedlbugscopyrightinstallationto': 1,\n",
       " 'install': 192,\n",
       " 'it': 662,\n",
       " 'right': 32,\n",
       " 'away': 5,\n",
       " 'for': 1393,\n",
       " 'all': 319,\n",
       " 'unix': 5,\n",
       " 'users': 48,\n",
       " 'linux': 21,\n",
       " 'macos': 48,\n",
       " 'etc': 26,\n",
       " 'typesudo': 1,\n",
       " 'curl': 4,\n",
       " 'l': 3,\n",
       " 'httpsytdlorgdownloadslatestyoutubedl': 3,\n",
       " 'o': 37,\n",
       " 'usrlocalbinyoutubedlsudo': 3,\n",
       " 'chmod': 3,\n",
       " 'arx': 3,\n",
       " 'usrlocalbinyoutubedlif': 1,\n",
       " 'you': 1376,\n",
       " 'do': 220,\n",
       " 'not': 458,\n",
       " 'have': 236,\n",
       " 'can': 785,\n",
       " 'alternatively': 4,\n",
       " 'use': 602,\n",
       " 'a': 2206,\n",
       " 'recent': 9,\n",
       " 'wgetsudo': 1,\n",
       " 'wget': 3,\n",
       " 'usrlocalbinyoutubedlwindows': 1,\n",
       " 'an': 479,\n",
       " 'exe': 6,\n",
       " 'file': 223,\n",
       " 'and': 2261,\n",
       " 'place': 20,\n",
       " 'in': 1677,\n",
       " 'any': 220,\n",
       " 'location': 16,\n",
       " 'on': 737,\n",
       " 'their': 80,\n",
       " 'path': 53,\n",
       " 'except': 14,\n",
       " 'systemrootsystem32': 1,\n",
       " 'eg': 63,\n",
       " 'put': 28,\n",
       " 'cwindowssystem32you': 1,\n",
       " 'also': 192,\n",
       " 'pipsudo': 1,\n",
       " 'h': 3,\n",
       " 'pip': 20,\n",
       " 'upgrade': 11,\n",
       " 'youtubedlthis': 1,\n",
       " 'command': 63,\n",
       " 'will': 473,\n",
       " 'update': 92,\n",
       " 'if': 477,\n",
       " 'already': 31,\n",
       " 'installed': 49,\n",
       " 'see': 183,\n",
       " 'the': 5108,\n",
       " 'pypi': 2,\n",
       " 'page': 46,\n",
       " 'more': 200,\n",
       " 'informationmacos': 1,\n",
       " 'with': 940,\n",
       " 'homebrewbrew': 1,\n",
       " 'youtubedlor': 1,\n",
       " 'macportssudo': 1,\n",
       " 'port': 12,\n",
       " 'youtubedlalternatively': 1,\n",
       " 'refer': 25,\n",
       " 'to': 3539,\n",
       " 'developer': 26,\n",
       " 'instructions': 37,\n",
       " 'how': 145,\n",
       " 'check': 82,\n",
       " 'out': 97,\n",
       " 'work': 88,\n",
       " 'git': 42,\n",
       " 'repository': 74,\n",
       " 'further': 22,\n",
       " 'options': 43,\n",
       " 'including': 59,\n",
       " 'pgp': 2,\n",
       " 'signatures': 4,\n",
       " 'pagedescriptionyoutubedl': 1,\n",
       " 'is': 1809,\n",
       " 'commandline': 5,\n",
       " 'program': 7,\n",
       " 'few': 33,\n",
       " 'sites': 9,\n",
       " 'requires': 36,\n",
       " 'python': 62,\n",
       " 'interpreter': 2,\n",
       " 'version': 165,\n",
       " '26': 11,\n",
       " '27': 21,\n",
       " '32': 8,\n",
       " 'platform': 27,\n",
       " 'specific': 52,\n",
       " 'should': 203,\n",
       " 'your': 753,\n",
       " 'box': 9,\n",
       " 'windows': 34,\n",
       " 'released': 59,\n",
       " 'public': 29,\n",
       " 'domain': 6,\n",
       " 'which': 236,\n",
       " 'means': 34,\n",
       " 'modify': 22,\n",
       " 'redistribute': 1,\n",
       " 'however': 33,\n",
       " 'likeyoutubedl': 1,\n",
       " 'url': 72,\n",
       " 'urloptionsh': 1,\n",
       " 'help': 64,\n",
       " 'print': 23,\n",
       " 'this': 639,\n",
       " 'text': 76,\n",
       " 'exitversion': 1,\n",
       " 'exitu': 1,\n",
       " 'latest': 44,\n",
       " 'make': 135,\n",
       " 'sure': 68,\n",
       " 'that': 765,\n",
       " 'sufficient': 3,\n",
       " 'permissions': 4,\n",
       " 'run': 188,\n",
       " 'sudo': 10,\n",
       " 'neededi': 1,\n",
       " 'ignoreerrors': 1,\n",
       " 'continue': 19,\n",
       " 'errors': 32,\n",
       " 'example': 206,\n",
       " 'skip': 14,\n",
       " 'unavailable': 6,\n",
       " 'playlistabortonerror': 1,\n",
       " 'abort': 6,\n",
       " 'downloading': 28,\n",
       " 'of': 1797,\n",
       " 'playlist': 24,\n",
       " 'line': 37,\n",
       " 'error': 140,\n",
       " 'occursdumpuseragent': 1,\n",
       " 'display': 44,\n",
       " 'current': 55,\n",
       " 'browser': 55,\n",
       " 'identificationlistextractors': 1,\n",
       " 'list': 101,\n",
       " 'supported': 75,\n",
       " 'extractorsextractordescriptions': 1,\n",
       " 'output': 81,\n",
       " 'descriptions': 2,\n",
       " 'extractorsforcegenericextractor': 1,\n",
       " 'force': 16,\n",
       " 'extraction': 18,\n",
       " 'generic': 16,\n",
       " 'extractordefaultsearch': 1,\n",
       " 'prefix': 7,\n",
       " 'unqualified': 1,\n",
       " 'urls': 17,\n",
       " 'gvsearch2': 1,\n",
       " 'downloads': 19,\n",
       " 'two': 78,\n",
       " 'google': 34,\n",
       " 'large': 31,\n",
       " 'apple': 28,\n",
       " 'value': 131,\n",
       " 'auto': 7,\n",
       " 'let': 80,\n",
       " 'guess': 4,\n",
       " 'autowarning': 1,\n",
       " 'emit': 8,\n",
       " 'warning': 14,\n",
       " 'when': 268,\n",
       " 'guessing': 1,\n",
       " 'just': 82,\n",
       " 'throws': 4,\n",
       " 'default': 201,\n",
       " 'fixuperror': 1,\n",
       " 'repairs': 1,\n",
       " 'broken': 3,\n",
       " 'but': 192,\n",
       " 'emits': 2,\n",
       " 'possible': 72,\n",
       " 'instead': 76,\n",
       " 'searchingignoreconfig': 1,\n",
       " 'read': 59,\n",
       " 'configuration': 64,\n",
       " 'files': 97,\n",
       " 'given': 45,\n",
       " 'global': 13,\n",
       " 'etcyoutubedlconf': 2,\n",
       " 'user': 125,\n",
       " 'configyoutube': 1,\n",
       " 'dlconfig': 1,\n",
       " 'appdatayoutubedlconfigtxt': 2,\n",
       " 'windowsconfiglocation': 1,\n",
       " 'either': 53,\n",
       " 'config': 26,\n",
       " 'its': 151,\n",
       " 'containing': 13,\n",
       " 'directoryflatplaylist': 1,\n",
       " 'extract': 20,\n",
       " 'only': 216,\n",
       " 'themmarkwatched': 1,\n",
       " 'mark': 10,\n",
       " 'watched': 3,\n",
       " 'youtube': 21,\n",
       " 'onlynomarkwatched': 1,\n",
       " 'onlynocolor': 1,\n",
       " 'color': 27,\n",
       " 'codes': 9,\n",
       " 'outputnetwork': 1,\n",
       " 'optionsproxy': 1,\n",
       " 'specified': 40,\n",
       " 'httphttpssocks': 1,\n",
       " 'proxy': 24,\n",
       " 'enable': 32,\n",
       " 'socks': 2,\n",
       " 'specify': 38,\n",
       " 'proper': 11,\n",
       " 'scheme': 11,\n",
       " 'socks51270011080': 1,\n",
       " 'pass': 72,\n",
       " 'empty': 3,\n",
       " 'string': 126,\n",
       " 'direct': 6,\n",
       " 'connectionsockettimeout': 1,\n",
       " 'seconds': 21,\n",
       " 'time': 97,\n",
       " 'wait': 6,\n",
       " 'before': 60,\n",
       " 'giving': 5,\n",
       " 'up': 105,\n",
       " 'secondssourceaddress': 1,\n",
       " 'ip': 14,\n",
       " 'clientside': 5,\n",
       " 'address': 15,\n",
       " 'bind': 13,\n",
       " 'to4': 1,\n",
       " 'forceipv4': 1,\n",
       " 'connections': 23,\n",
       " 'via': 76,\n",
       " 'ipv46': 1,\n",
       " 'forceipv6': 1,\n",
       " 'ipv6geo': 1,\n",
       " 'restrictiongeoverificationproxy': 1,\n",
       " 'verify': 12,\n",
       " 'some': 151,\n",
       " 'georestricted': 1,\n",
       " 'by': 466,\n",
       " 'none': 16,\n",
       " 'option': 40,\n",
       " 'present': 15,\n",
       " 'used': 198,\n",
       " 'actual': 12,\n",
       " 'downloadinggeobypass': 1,\n",
       " 'bypass': 5,\n",
       " 'geographic': 4,\n",
       " 'restriction': 9,\n",
       " 'faking': 2,\n",
       " 'xforwardedfor': 2,\n",
       " 'http': 34,\n",
       " 'headernogeobypass': 1,\n",
       " 'headergeobypasscountry': 1,\n",
       " 'code': 208,\n",
       " 'explicitly': 20,\n",
       " 'provided': 47,\n",
       " 'twoletter': 1,\n",
       " 'iso': 5,\n",
       " '31662': 1,\n",
       " 'country': 3,\n",
       " 'codegeobypassipblock': 1,\n",
       " 'ipblock': 1,\n",
       " 'block': 18,\n",
       " 'cidr': 1,\n",
       " 'notationvideo': 1,\n",
       " 'selectionplayliststart': 1,\n",
       " 'number': 102,\n",
       " 'start': 60,\n",
       " 'at': 198,\n",
       " '1playlistend': 1,\n",
       " 'end': 29,\n",
       " 'lastplaylistitems': 1,\n",
       " 'itemspec': 1,\n",
       " 'items': 41,\n",
       " 'indices': 2,\n",
       " 'separated': 9,\n",
       " 'commas': 2,\n",
       " 'like': 160,\n",
       " 'playlistitems': 2,\n",
       " '1258': 1,\n",
       " 'want': 155,\n",
       " 'indexed': 3,\n",
       " '1': 62,\n",
       " '2': 51,\n",
       " '5': 26,\n",
       " '8': 21,\n",
       " 'range': 11,\n",
       " '1371013': 1,\n",
       " 'index': 38,\n",
       " '3': 38,\n",
       " '7': 15,\n",
       " '10': 16,\n",
       " '11': 16,\n",
       " '12': 5,\n",
       " '13matchtitle': 1,\n",
       " 'regex': 7,\n",
       " 'matching': 11,\n",
       " 'titles': 3,\n",
       " 'caseless': 2,\n",
       " 'substringrejecttitle': 1,\n",
       " 'substringmaxdownloads': 1,\n",
       " 'after': 80,\n",
       " 'filesminfilesize': 1,\n",
       " 'size': 37,\n",
       " 'smaller': 10,\n",
       " 'than': 81,\n",
       " '50k': 3,\n",
       " '446mmaxfilesize': 1,\n",
       " 'larger': 8,\n",
       " '446mdate': 1,\n",
       " 'date': 27,\n",
       " 'uploaded': 9,\n",
       " 'datedatebefore': 1,\n",
       " 'ie': 39,\n",
       " 'inclusivedateafter': 1,\n",
       " 'inclusiveminviews': 1,\n",
       " 'count': 25,\n",
       " 'less': 20,\n",
       " 'viewsmaxviews': 1,\n",
       " 'viewsmatchfilter': 1,\n",
       " 'filter': 16,\n",
       " 'key': 41,\n",
       " 'template': 30,\n",
       " 'available': 123,\n",
       " 'keys': 14,\n",
       " 'match': 27,\n",
       " 'commentcount': 1,\n",
       " 'works': 33,\n",
       " 'compare': 6,\n",
       " 'against': 20,\n",
       " 'literal': 3,\n",
       " 'uploader': 3,\n",
       " 'mike': 4,\n",
       " 'smith': 2,\n",
       " 'require': 31,\n",
       " 'multiple': 72,\n",
       " 'matches': 12,\n",
       " 'values': 43,\n",
       " 'are': 766,\n",
       " 'known': 14,\n",
       " 'excluded': 3,\n",
       " 'unless': 11,\n",
       " 'question': 12,\n",
       " 'operator': 9,\n",
       " 'been': 52,\n",
       " 'liked': 1,\n",
       " '100': 26,\n",
       " 'times': 14,\n",
       " 'disliked': 1,\n",
       " '50': 11,\n",
       " 'dislike': 1,\n",
       " 'functionality': 29,\n",
       " 'service': 47,\n",
       " 'who': 17,\n",
       " 'description': 31,\n",
       " 'matchfilter': 1,\n",
       " 'likecount': 1,\n",
       " 'dislikecount': 1,\n",
       " 'noplaylist': 1,\n",
       " 'refers': 6,\n",
       " 'playlistyesplaylist': 1,\n",
       " 'playlistagelimit': 1,\n",
       " 'years': 3,\n",
       " 'suitable': 3,\n",
       " 'agedownloadarchive': 1,\n",
       " 'listed': 16,\n",
       " 'archive': 10,\n",
       " 'record': 10,\n",
       " 'ids': 4,\n",
       " 'downloaded': 30,\n",
       " 'itincludeads': 1,\n",
       " 'advertisements': 1,\n",
       " 'as': 690,\n",
       " 'well': 41,\n",
       " 'experimentaldownload': 1,\n",
       " 'optionsr': 1,\n",
       " 'limitrate': 1,\n",
       " 'rate': 15,\n",
       " 'maximum': 16,\n",
       " 'bytes': 4,\n",
       " 'per': 14,\n",
       " 'second': 20,\n",
       " '42mr': 1,\n",
       " 'retries': 5,\n",
       " 'infinitefragmentretries': 1,\n",
       " 'fragment': 6,\n",
       " 'infinite': 3,\n",
       " 'dash': 10,\n",
       " 'hlsnative': 2,\n",
       " 'ismskipunavailablefragments': 1,\n",
       " 'fragments': 10,\n",
       " 'ismabortonunavailablefragment': 1,\n",
       " 'availablekeepfragments': 1,\n",
       " 'keep': 34,\n",
       " 'disk': 20,\n",
       " 'finished': 8,\n",
       " 'erased': 2,\n",
       " 'defaultbuffersize': 1,\n",
       " 'buffer': 14,\n",
       " '1024': 3,\n",
       " '16k': 1,\n",
       " '1024noresizebuffer': 1,\n",
       " 'automatically': 49,\n",
       " 'adjust': 3,\n",
       " 'resized': 2,\n",
       " 'initial': 22,\n",
       " 'sizehttpchunksize': 1,\n",
       " 'chunk': 2,\n",
       " 'chunkbased': 1,\n",
       " '10485760': 1,\n",
       " '10m': 1,\n",
       " 'disabled': 6,\n",
       " 'may': 136,\n",
       " 'be': 705,\n",
       " 'useful': 29,\n",
       " 'bypassing': 1,\n",
       " 'bandwidth': 5,\n",
       " 'throttling': 2,\n",
       " 'imposed': 2,\n",
       " 'webserver': 2,\n",
       " 'experimentalplaylistreverse': 1,\n",
       " 'reverse': 2,\n",
       " 'orderplaylistrandom': 1,\n",
       " 'random': 7,\n",
       " 'orderxattrsetfilesize': 1,\n",
       " 'set': 158,\n",
       " 'xattribute': 1,\n",
       " 'ytdlfilesize': 1,\n",
       " 'expected': 10,\n",
       " 'sizehlsprefernative': 1,\n",
       " 'native': 56,\n",
       " 'hls': 11,\n",
       " 'downloader': 12,\n",
       " 'ffmpeghlspreferffmpeg': 1,\n",
       " 'ffmpeg': 18,\n",
       " 'downloaderhlsusempegts': 1,\n",
       " 'mpegts': 1,\n",
       " 'container': 35,\n",
       " 'allowing': 14,\n",
       " 'play': 33,\n",
       " 'while': 48,\n",
       " 'players': 1,\n",
       " 'able': 34,\n",
       " 'itexternaldownloader': 1,\n",
       " 'external': 20,\n",
       " 'currently': 41,\n",
       " 'supports': 47,\n",
       " 'aria2cavconvaxelcurlffmpeghttpiewgetexternaldownloaderargs': 1,\n",
       " 'args': 5,\n",
       " 'give': 14,\n",
       " 'these': 93,\n",
       " 'arguments': 16,\n",
       " 'downloaderfilesystem': 1,\n",
       " 'optionsa': 1,\n",
       " 'batchfile': 1,\n",
       " 'stdin': 2,\n",
       " 'one': 122,\n",
       " 'lines': 23,\n",
       " 'starting': 15,\n",
       " 'considered': 11,\n",
       " 'comments': 17,\n",
       " 'ignoredid': 1,\n",
       " 'id': 35,\n",
       " 'nameo': 1,\n",
       " 'filename': 8,\n",
       " 'infoautonumberstart': 1,\n",
       " 'autonumbers': 1,\n",
       " '1restrictfilenames': 1,\n",
       " 'restrict': 3,\n",
       " 'filenames': 1,\n",
       " 'ascii': 2,\n",
       " 'characters': 12,\n",
       " 'avoid': 24,\n",
       " 'spaces': 5,\n",
       " 'filenamesw': 1,\n",
       " 'nooverwrites': 1,\n",
       " 'overwrite': 2,\n",
       " 'filesc': 1,\n",
       " 'resume': 10,\n",
       " 'partially': 4,\n",
       " 'possiblenocontinue': 1,\n",
       " 'restart': 6,\n",
       " 'beginningnopart': 1,\n",
       " 'part': 43,\n",
       " 'write': 60,\n",
       " 'directly': 50,\n",
       " 'into': 175,\n",
       " 'filenomtime': 1,\n",
       " 'lastmodified': 1,\n",
       " 'header': 9,\n",
       " 'modification': 1,\n",
       " 'timewritedescription': 1,\n",
       " 'filewriteinfojson': 1,\n",
       " 'metadata': 29,\n",
       " 'infojson': 1,\n",
       " 'filewriteannotations': 1,\n",
       " 'annotations': 5,\n",
       " 'annotationsxml': 1,\n",
       " 'fileloadinfojson': 1,\n",
       " 'json': 19,\n",
       " 'information': 76,\n",
       " 'created': 52,\n",
       " 'writeinfojson': 1,\n",
       " 'optioncookies': 1,\n",
       " 'cookies': 18,\n",
       " 'dump': 5,\n",
       " 'cookie': 4,\n",
       " 'jar': 13,\n",
       " 'incachedir': 1,\n",
       " 'dir': 3,\n",
       " 'filesystem': 7,\n",
       " 'where': 61,\n",
       " 'store': 85,\n",
       " 'permanently': 1,\n",
       " 'xdgcachehomeyoutubedl': 1,\n",
       " 'cacheyoutubedl': 1,\n",
       " 'moment': 11,\n",
       " 'player': 33,\n",
       " 'obfuscated': 1,\n",
       " 'cached': 7,\n",
       " 'changenocachedir': 1,\n",
       " 'disable': 13,\n",
       " 'cachingrmcachedir': 1,\n",
       " 'delete': 11,\n",
       " 'cache': 40,\n",
       " 'filesthumbnail': 1,\n",
       " 'imageswritethumbnail': 1,\n",
       " 'thumbnail': 7,\n",
       " 'image': 138,\n",
       " 'diskwriteallthumbnails': 1,\n",
       " 'formats': 22,\n",
       " 'disklistthumbnails': 1,\n",
       " 'simulate': 13,\n",
       " 'formatsverbosity': 1,\n",
       " 'simulation': 1,\n",
       " 'optionsq': 1,\n",
       " 'quiet': 13,\n",
       " 'activate': 5,\n",
       " 'modenowarnings': 1,\n",
       " 'ignore': 8,\n",
       " 'warningss': 1,\n",
       " 'anything': 14,\n",
       " 'diskskipdownload': 1,\n",
       " 'videog': 1,\n",
       " 'geturl': 1,\n",
       " 'urle': 1,\n",
       " 'gettitle': 1,\n",
       " 'titlegetid': 1,\n",
       " 'idgetthumbnail': 1,\n",
       " 'urlgetdescription': 1,\n",
       " 'descriptiongetduration': 1,\n",
       " 'lengthgetfilename': 1,\n",
       " 'filenamegetformat': 1,\n",
       " 'formatj': 1,\n",
       " 'dumpjson': 1,\n",
       " 'keysj': 1,\n",
       " 'dumpsinglejson': 1,\n",
       " 'each': 96,\n",
       " 'argument': 23,\n",
       " 'whole': 20,\n",
       " 'single': 58,\n",
       " 'lineprintjson': 1,\n",
       " 'still': 42,\n",
       " 'being': 48,\n",
       " 'downloadednewline': 1,\n",
       " 'progress': 14,\n",
       " 'bar': 10,\n",
       " 'new': 188,\n",
       " 'linesnoprogress': 1,\n",
       " 'barconsoletitle': 1,\n",
       " 'console': 9,\n",
       " 'titlebarv': 1,\n",
       " 'verbose': 5,\n",
       " 'various': 17,\n",
       " 'debugging': 13,\n",
       " 'informationdumppages': 1,\n",
       " 'pages': 13,\n",
       " 'encoded': 3,\n",
       " 'using': 389,\n",
       " 'base64': 3,\n",
       " 'debug': 20,\n",
       " 'problems': 18,\n",
       " 'very': 54,\n",
       " 'verbosewritepages': 1,\n",
       " 'intermediary': 1,\n",
       " 'directory': 89,\n",
       " 'problemsprinttraffic': 1,\n",
       " 'sent': 8,\n",
       " 'trafficc': 1,\n",
       " 'callhome': 2,\n",
       " 'contact': 19,\n",
       " 'server': 70,\n",
       " 'debuggingnocallhome': 1,\n",
       " 'debuggingworkaroundsencoding': 1,\n",
       " 'encoding': 5,\n",
       " 'experimentalnocheckcertificate': 1,\n",
       " 'suppress': 4,\n",
       " 'https': 10,\n",
       " 'certificate': 4,\n",
       " 'validationpreferinsecure': 1,\n",
       " 'unencrypted': 2,\n",
       " 'connection': 49,\n",
       " 'retrieve': 19,\n",
       " 'about': 114,\n",
       " 'youtubeuseragent': 1,\n",
       " 'ua': 1,\n",
       " 'custom': 59,\n",
       " 'agentreferer': 1,\n",
       " 'referer': 1,\n",
       " 'access': 67,\n",
       " 'restricted': 3,\n",
       " 'domainaddheader': 1,\n",
       " 'fieldvalue': 1,\n",
       " 'colon': 1,\n",
       " 'timesbidiworkaround': 1,\n",
       " 'around': 27,\n",
       " 'terminals': 1,\n",
       " 'lack': 5,\n",
       " 'bidirectional': 2,\n",
       " 'support': 168,\n",
       " 'bidiv': 1,\n",
       " 'fribidi': 1,\n",
       " 'executable': 5,\n",
       " 'pathsleepinterval': 1,\n",
       " 'sleep': 6,\n",
       " 'alone': 1,\n",
       " 'lower': 7,\n",
       " 'bound': 6,\n",
       " 'randomized': 2,\n",
       " 'minimum': 20,\n",
       " 'along': 19,\n",
       " 'maxsleepintervalmaxsleepinterval': 1,\n",
       " 'upper': 1,\n",
       " 'must': 66,\n",
       " 'minsleepintervalvideo': 1,\n",
       " 'format': 94,\n",
       " 'optionsf': 1,\n",
       " 'selection': 11,\n",
       " 'infoallformats': 1,\n",
       " 'formatspreferfreeformats': 1,\n",
       " 'prefer': 11,\n",
       " 'free': 36,\n",
       " 'requestedf': 1,\n",
       " 'listformats': 2,\n",
       " 'requested': 4,\n",
       " 'videosyoutubeskipdashmanifest': 1,\n",
       " 'manifests': 2,\n",
       " 'related': 12,\n",
       " 'data': 238,\n",
       " 'videosmergeoutputformat': 1,\n",
       " 'merge': 18,\n",
       " 'required': 37,\n",
       " 'bestvideobestaudio': 3,\n",
       " 'mkv': 2,\n",
       " 'mp4': 14,\n",
       " 'ogg': 2,\n",
       " 'webm': 6,\n",
       " 'flv': 2,\n",
       " 'ignored': 2,\n",
       " 'no': 83,\n",
       " 'requiredsubtitle': 1,\n",
       " 'optionswritesub': 1,\n",
       " 'subtitle': 4,\n",
       " 'filewriteautosub': 1,\n",
       " 'generated': 21,\n",
       " 'onlyallsubs': 1,\n",
       " 'subtitles': 6,\n",
       " 'videolistsubs': 1,\n",
       " 'videosubformat': 1,\n",
       " 'accepts': 5,\n",
       " 'preference': 4,\n",
       " 'srt': 2,\n",
       " 'asssrtbestsublang': 1,\n",
       " 'langs': 1,\n",
       " 'languages': 13,\n",
       " 'optional': 26,\n",
       " 'subs': 1,\n",
       " 'language': 51,\n",
       " 'tagsauthentication': 1,\n",
       " 'optionsu': 1,\n",
       " 'username': 6,\n",
       " 'login': 16,\n",
       " 'account': 8,\n",
       " 'idp': 1,\n",
       " 'password': 21,\n",
       " 'left': 20,\n",
       " 'ask': 19,\n",
       " 'interactively2': 1,\n",
       " 'twofactor': 3,\n",
       " 'authentication': 9,\n",
       " 'coden': 1,\n",
       " 'netrc': 7,\n",
       " 'datavideopassword': 1,\n",
       " 'vimeo': 2,\n",
       " 'smotri': 1,\n",
       " 'youkuadobe': 1,\n",
       " 'optionsapmso': 1,\n",
       " 'mso': 1,\n",
       " 'adobe': 5,\n",
       " 'multiplesystem': 4,\n",
       " 'tv': 4,\n",
       " 'provider': 11,\n",
       " 'identifier': 15,\n",
       " 'aplistmso': 1,\n",
       " 'msosapusername': 1,\n",
       " 'loginappassword': 1,\n",
       " 'interactivelyaplistmso': 1,\n",
       " 'operatorspostprocessing': 1,\n",
       " 'optionsx': 1,\n",
       " 'extractaudio': 1,\n",
       " 'convert': 14,\n",
       " 'audioonly': 2,\n",
       " 'avconv': 6,\n",
       " 'ffprobe': 2,\n",
       " 'avprobeaudioformat': 1,\n",
       " 'audio': 43,\n",
       " 'best': 70,\n",
       " 'aac': 2,\n",
       " 'flac': 1,\n",
       " 'mp3': 4,\n",
       " 'm4a': 2,\n",
       " 'opus': 2,\n",
       " 'vorbis': 1,\n",
       " 'wav': 2,\n",
       " 'effect': 26,\n",
       " 'without': 107,\n",
       " 'xaudioquality': 1,\n",
       " 'quality': 22,\n",
       " 'ffmpegavconv': 2,\n",
       " 'insert': 1,\n",
       " 'between': 100,\n",
       " '0': 61,\n",
       " 'better': 32,\n",
       " '9': 121,\n",
       " 'worse': 3,\n",
       " 'vbr': 1,\n",
       " 'bitrate': 15,\n",
       " '128k': 1,\n",
       " '5recodevideo': 1,\n",
       " 'encode': 2,\n",
       " 'another': 39,\n",
       " 'necessary': 16,\n",
       " 'mp4flvoggwebmmkvavipostprocessorargs': 1,\n",
       " 'postprocessork': 1,\n",
       " 'keepvideo': 1,\n",
       " 'post': 12,\n",
       " 'processing': 22,\n",
       " 'defaultnopostoverwrites': 1,\n",
       " 'postprocessed': 2,\n",
       " 'overwritten': 1,\n",
       " 'defaultembedsubs': 1,\n",
       " 'embed': 11,\n",
       " 'videosembedthumbnail': 1,\n",
       " 'cover': 6,\n",
       " 'artaddmetadata': 1,\n",
       " 'filemetadatafromtitle': 1,\n",
       " 'parse': 11,\n",
       " 'additional': 39,\n",
       " 'song': 1,\n",
       " 'title': 64,\n",
       " 'artist': 1,\n",
       " 'syntax': 27,\n",
       " 'same': 110,\n",
       " 'regular': 28,\n",
       " 'expression': 12,\n",
       " 'named': 34,\n",
       " 'capture': 4,\n",
       " 'groups': 8,\n",
       " 'parsed': 5,\n",
       " 'parameters': 21,\n",
       " 'replace': 10,\n",
       " 'existing': 25,\n",
       " 'metadatafrom': 1,\n",
       " 'artists': 3,\n",
       " 'coldplay': 1,\n",
       " 'paradise': 1,\n",
       " 'metadatafromtitle': 1,\n",
       " 'partist': 1,\n",
       " 'ptitlexattrs': 1,\n",
       " 'xattrs': 1,\n",
       " 'dublin': 1,\n",
       " 'core': 39,\n",
       " 'xdg': 1,\n",
       " 'standardsfixup': 1,\n",
       " 'policy': 6,\n",
       " 'correct': 18,\n",
       " 'faults': 1,\n",
       " 'never': 30,\n",
       " 'nothing': 12,\n",
       " 'warn': 5,\n",
       " 'detectorwarn': 1,\n",
       " 'fix': 9,\n",
       " 'we': 239,\n",
       " 'otherwisepreferavconv': 1,\n",
       " 'over': 54,\n",
       " 'running': 65,\n",
       " 'postprocessorspreferffmpeg': 1,\n",
       " 'postprocessors': 2,\n",
       " 'defaultffmpeglocation': 1,\n",
       " 'binary': 33,\n",
       " 'directoryexec': 1,\n",
       " 'cmd': 2,\n",
       " 'execute': 17,\n",
       " 'postprocessing': 1,\n",
       " 'similar': 27,\n",
       " 'finds': 2,\n",
       " 'exec': 3,\n",
       " 'adb': 1,\n",
       " 'push': 18,\n",
       " 'sdcardmusic': 1,\n",
       " 'rm': 2,\n",
       " 'convertsubs': 1,\n",
       " 'srtassvttlrcconfigurationyou': 1,\n",
       " 'configure': 20,\n",
       " 'placing': 1,\n",
       " 'system': 57,\n",
       " 'wide': 8,\n",
       " 'located': 7,\n",
       " 'configyoutubedlconfig': 1,\n",
       " 'locations': 2,\n",
       " 'cusersuser': 2,\n",
       " 'nameyoutubedlconf': 1,\n",
       " 'note': 67,\n",
       " 'exist': 8,\n",
       " 'so': 153,\n",
       " 'need': 252,\n",
       " 'create': 130,\n",
       " 'yourselffor': 1,\n",
       " 'following': 136,\n",
       " 'always': 44,\n",
       " 'copy': 36,\n",
       " 'mtime': 1,\n",
       " 'save': 19,\n",
       " 'under': 83,\n",
       " 'movies': 3,\n",
       " 'home': 8,\n",
       " 'audiox': 1,\n",
       " 'mtimenomtime': 1,\n",
       " 'proxyproxy': 2,\n",
       " '1270013128': 1,\n",
       " 'directoryo': 1,\n",
       " 'moviestitlesextsnote': 1,\n",
       " 'aka': 4,\n",
       " 'switches': 2,\n",
       " 'calls': 21,\n",
       " 'thus': 14,\n",
       " 'there': 90,\n",
       " 'whitespace': 1,\n",
       " 'proxyyou': 1,\n",
       " 'ignoreconfig': 1,\n",
       " 'particular': 33,\n",
       " 'runyou': 1,\n",
       " 'configlocation': 1,\n",
       " 'runauthentication': 1,\n",
       " 'fileyou': 2,\n",
       " 'automatic': 9,\n",
       " 'credentials': 6,\n",
       " 'storage': 10,\n",
       " 'extractors': 1,\n",
       " 'providing': 11,\n",
       " 'order': 59,\n",
       " 'every': 46,\n",
       " 'execution': 16,\n",
       " 'prevent': 21,\n",
       " 'tracking': 3,\n",
       " 'plain': 12,\n",
       " 'passwords': 1,\n",
       " 'shell': 17,\n",
       " 'history': 32,\n",
       " 'achieve': 7,\n",
       " 'extractor': 23,\n",
       " 'basis': 4,\n",
       " 'readwrite': 1,\n",
       " 'youtouch': 1,\n",
       " 'homenetrcchmod': 1,\n",
       " 'arwxurw': 1,\n",
       " 'homenetrcafter': 1,\n",
       " 'add': 149,\n",
       " 'name': 115,\n",
       " 'lowercasemachine': 1,\n",
       " 'passwordfor': 1,\n",
       " 'examplemachine': 1,\n",
       " 'myaccountgmailcom': 1,\n",
       " 'myyoutubepasswordmachine': 1,\n",
       " 'twitch': 1,\n",
       " 'mytwitchaccountname': 1,\n",
       " 'mytwitchpasswordto': 1,\n",
       " 'fileon': 1,\n",
       " 'setup': 27,\n",
       " 'environment': 48,\n",
       " 'variable': 17,\n",
       " 'manually': 17,\n",
       " 'exampleset': 1,\n",
       " 'homeuserprofileoutput': 1,\n",
       " 'templatethe': 1,\n",
       " 'allows': 39,\n",
       " 'indicate': 7,\n",
       " 'namestldr': 1,\n",
       " 'navigate': 11,\n",
       " 'me': 13,\n",
       " 'examplesthe': 2,\n",
       " 'basic': 25,\n",
       " 'usage': 29,\n",
       " 'funnyvideoflv': 1,\n",
       " 'httpssomevideo': 1,\n",
       " 'contain': 20,\n",
       " 'special': 18,\n",
       " 'sequences': 9,\n",
       " 'replaced': 5,\n",
       " 'formatted': 5,\n",
       " 'according': 6,\n",
       " 'formatting': 9,\n",
       " 'operations': 17,\n",
       " 'names': 17,\n",
       " 'name05d': 1,\n",
       " 'clarify': 1,\n",
       " 'percent': 5,\n",
       " 'symbol': 6,\n",
       " 'followed': 8,\n",
       " 'parentheses': 3,\n",
       " 'allowed': 17,\n",
       " 'sequence': 14,\n",
       " 'type': 106,\n",
       " 'areid': 1,\n",
       " 'identifiertitle': 2,\n",
       " 'titleurl': 2,\n",
       " 'urlext': 1,\n",
       " 'extensionalttitle': 1,\n",
       " 'secondary': 1,\n",
       " 'videodisplayid': 1,\n",
       " 'alternative': 7,\n",
       " 'videouploader': 1,\n",
       " 'full': 38,\n",
       " 'uploaderlicense': 1,\n",
       " 'license': 50,\n",
       " 'licensed': 19,\n",
       " 'undercreator': 1,\n",
       " 'creator': 6,\n",
       " 'videoreleasedate': 1,\n",
       " 'yyyymmdd': 2,\n",
       " 'was': 64,\n",
       " 'releasedtimestamp': 1,\n",
       " 'numeric': 35,\n",
       " 'timestamp': 2,\n",
       " 'became': 2,\n",
       " 'availableuploaddate': 1,\n",
       " 'upload': 14,\n",
       " 'yyyymmdduploaderid': 1,\n",
       " 'nickname': 2,\n",
       " 'uploaderchannel': 1,\n",
       " 'channel': 14,\n",
       " 'onchannelid': 1,\n",
       " 'channellocation': 1,\n",
       " 'physical': 3,\n",
       " 'filmedduration': 1,\n",
       " 'length': 4,\n",
       " 'secondsviewcount': 1,\n",
       " 'many': 59,\n",
       " 'platformlikecount': 1,\n",
       " 'positive': 7,\n",
       " 'ratings': 2,\n",
       " 'videodislikecount': 1,\n",
       " 'negative': 6,\n",
       " 'videorepostcount': 1,\n",
       " 'reposts': 1,\n",
       " 'videoaveragerating': 1,\n",
       " 'average': 7,\n",
       " 'rating': 1,\n",
       " 'scale': 17,\n",
       " 'depends': 14,\n",
       " 'webpagecommentcount': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "most_freq = heapq.nlargest(200, wordfreq, key=wordfreq.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for sentence in corpus:\n",
    "    sentence_tokens = nltk.word_tokenize(sentence)\n",
    "    sent_vec = []\n",
    "    for token in most_freq:\n",
    "        if token in sentence_tokens:\n",
    "            sent_vec.append(1)\n",
    "        else:\n",
    "            sent_vec.append(0)\n",
    "    sentence_vectors.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = np.asarray(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      java  javascript  python  swift\n",
      "predicted                                  \n",
      "java          20           0       0      0\n",
      "javascript     0          20       0      0\n",
      "python         0           0      20      0\n",
      "swift          0           0       0     20\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        java       1.00      1.00      1.00        20\n",
      "  javascript       1.00      1.00      1.00        20\n",
      "      python       1.00      1.00      1.00        20\n",
      "       swift       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Validate (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      java  javascript  python  swift\n",
      "predicted                                  \n",
      "java           5           1       1      0\n",
      "javascript     0           4       0      1\n",
      "python         0           0       4      0\n",
      "swift          0           0       0      4\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        java       0.71      1.00      0.83         5\n",
      "  javascript       0.80      0.80      0.80         5\n",
      "      python       1.00      0.80      0.89         5\n",
      "       swift       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF-IDF\n",
    "- TF: Term Frequency; how often a word appears in a document.\n",
    "- IDF: Inverse Documnet Frequency; a measure based on in how many documents will a word appear.\n",
    "- TF-IDF: A combination of the two measures above.\n",
    "\n",
    "\n",
    "## TF_iDF Modeling\n",
    "- create term frequency on whole df\n",
    "- split into train and test for X and y\n",
    "- predict on train\n",
    "- predict on test\n",
    "- evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.filtered)\n",
    "y = df.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      java  javascript  python  swift\n",
      "predicted                                  \n",
      "java          20           0       0      0\n",
      "javascript     0          20       0      0\n",
      "python         0           0      20      0\n",
      "swift          0           0       0     20\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        java       1.00      1.00      1.00        20\n",
      "  javascript       1.00      1.00      1.00        20\n",
      "      python       1.00      1.00      1.00        20\n",
      "       swift       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Validate (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      java  javascript  python  swift\n",
      "predicted                                  \n",
      "java           2           1       0      0\n",
      "javascript     1           3       0      0\n",
      "python         1           1       5      0\n",
      "swift          1           0       0      5\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        java       0.67      0.40      0.50         5\n",
      "  javascript       0.75      0.60      0.67         5\n",
      "      python       0.71      1.00      0.83         5\n",
      "       swift       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.74      0.75      0.73        20\n",
      "weighted avg       0.74      0.75      0.73        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency (TF)\n",
    "Term frequency can be calculated in a number of ways, all of which reflect how frequently a word appears in a document.\n",
    "\n",
    "- Raw Count: This is simply the count of the number of occurances of each word.\n",
    "- Frequency: The number of times each word appears divided by the total number of words.\n",
    "- Augmented Frequency: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents.  \n",
    "\n",
    "Would another way increase performance on validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "Conclusions:  \n",
    "Next Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusions <a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Back to Top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
